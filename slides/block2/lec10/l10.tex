\input{../../common/slide-common-header.tex}
\input{../../common/slide-plan.tex}

\title[]{Lecture \langMMNum: \langMMTopic}
\subtitle[]{\langMMKey}
\author[]{Alexander Filatov\\ filatovaur@gmail.com}

\date{}

\begin{document}

\begin{frame}
  \titlepage
  \url{https://github.com/Svazars/parallel-programming/blob/main/slides/pdf/l10.pdf}
\end{frame}


\begin{frame}{In previous episodes: homework}
"Is Parallel Programming Hard, And, If So, What Can You Do About It" \ (perfbook) 

Appendix B "Why Memory Barriers?"

\begin{itemize}
    \item section B.1 ''Cache Structure''. Be ready to draw and explain what is associative hardware cache.
    \item section B.2.4 ''MESI Protocol Example''
\end{itemize}
\end{frame}

\begin{frame}{In previous episodes}

Abstractions and algorithms (high level)
\begin{itemize} 
 \item Race conditions, deadlocks, missed signals, ABA problem
 \item Events, Precedence, Consistency
 \item Progress conditions: wait-free, lock-free, obstruction-free, starvation-free, deadlock-free 
 \item Read-Modify-Write operations
\end{itemize}

Programmers need at least: \textbf{Linearizability} (composability of different modules)

Hardware (low level)
\begin{itemize}    
    \item Cache coherency protocol: states, transitions, message passing
    \item Store buffering, Load buffering, Invalidate Queues, Interconnect topology
    \item Reorderings of memory operations on independent memory locations
    \item Weak (relaxed) consistency
\end{itemize}

Hardware provides at most: \textbf{Coherence} (linear order of writes for particular location)

\end{frame}

\begin{frame}{The Gap}

\pause

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=4cm,yshift=1cm] at (current page.center) {\includegraphics[width=0.4\textwidth]{./pics/unicorn.png}};
\end{tikzpicture}

\pause

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=-5cm,yshift=-0cm] at (current page.center) {\includegraphics[width=0.6\textwidth]{./pics/mordor.png}};
\end{tikzpicture}

\pause

\begin{tikzpicture}[remember picture,overlay]
\node[xshift=1cm,yshift=-2cm] at (current page.center) {\includegraphics[width=0.4\textwidth]{./pics/bridge2.png}};
\end{tikzpicture}

\end{frame}

\begin{frame}{Bridging the gap}

High-level concurrent programming focuses on design-level problems:
\begin{itemize}
  \pause \item separating function/computation and carrier/executor (\texttt{Future}, \texttt{Executor})
  \pause \item providing contracts and interfaces rather than particular implementations
  \pause \item composability of concurrent modules (deadlock avoidance, restartable transactions)
  \pause \item avoiding logic errors (race condition, unsynchronized data access, resource leaks)
  \pause \item user-visible metrics (responsiveness, CPU utilization, memory consumption)
  \pause \item error recovery, logging, graceful degradation
\end{itemize}

\pause
Low-level concurrent programming focuses on performance and location-level consistency:
\begin{itemize}
  \pause \item scalability under contention
  \pause \item effective usage of scheduling quantum 
  \pause \item avoiding false sharing, minimizing true sharing
  \pause \item replication-friendly data structures
  \pause \item appropriate and lightweight memory barriers  
\end{itemize}
\end{frame}


\begin{frame}[t,noframenumbering]{Bridging the gap}

\begin{itemize}
  \item High level concurrent programming focuses on design-level problems
  \item Low level concurrent programming focuses on performance and location-level consistency
  \pause \item Any programming language need to balance between low-level and high-level
\end{itemize}

\pause

There is no \textit{perfect} programming language. \pause But some languages
\begin{itemize}
  \pause
  \item avoid most of concurrency pitfalls via source-level constraints \pause (expressive power?)
  \pause
  \item simplify writing safe concurrent programs \pause (performance?)
  \pause
  \item allow to write hardware-agnostic and high-performant concurrent programs \pause (bugs?)
  \pause
  \item were not designed for modern concurrency \pause (single-threaded?)
\end{itemize}

\pause

As a professional, you should be able to use any tool, not only "the favourite" \ one. 

\end{frame}


\begin{frame}{Supplementary materials}

Unconditional benefit
\begin{itemize}
  \item "Threads Cannot be Implemented as a Library"\ by Hans-J. Boehm\footnote{\tiny\url{https://www.hboehm.info/misc_slides/pldi05_threads.pdf}}
  \url{https://courses.cs.washington.edu/courses/cse590p/05au/HPL-2004-209.pdf}

  \item "Memory Models"\ series by Russ Cox \url{https://research.swtch.com/mm}
  \item Herb Sutter, C++ and Beyond 2012, "Atomic Weapons"\ series \url{https://youtu.be/A8eCGOqgvH4}    
  \item Роман Елизаров, "Многопоточное программирование — теория и практика"\ \url{https://youtu.be/mf4lC6TpclM}
\end{itemize}

Advanced material
\begin{itemize}
  \item "Using JDK 9 Memory Order Modes" \ by Doug Lea \url{https://gee.cs.oswego.edu/dl/html/j9mm.html}
  \item Aleksey Shipilëv, JMM series \url{https://shipilev.net}
\end{itemize}

\end{frame}


\begin{frame}{Lecture plan}
\tableofcontents
\end{frame}


\section{Compiler optimizations}
\showTOC


\begin{frame}[t,fragile]{Inventing reads}

\begin{tabular}{p{0.5\textwidth} p{0.5\textwidth}}

\begin{minted}[fontsize=\small]{c}
static int a;
void foo_1() {
  while (true) {
    int tmp = a;
    if (tmp == 0) break;
    do_something_with(tmp);
  }
}
\end{minted}

&

\end{tabular}

\pause
Could compiler use less registers for intermediate operations?

\end{frame}

\begin{frame}[t,fragile,noframenumbering]{Inventing reads}

\begin{tabular}{p{0.5\textwidth} p{0.5\textwidth}}

\begin{minted}[fontsize=\small]{c}
static int a;
void foo_1() {
  while (true) {
    int tmp = a;
    if (tmp == 0) break;
    do_something_with(tmp);
  }
}
\end{minted}

&
\begin{minted}[fontsize=\small]{c}
static int a;
void foo_2() {
  while (true) {

    if (a == 0) break;
    do_something_with(a);
  }
}
\end{minted}

\end{tabular}

Could compiler use less registers for intermediate operations?

\end{frame}


\begin{frame}[t,fragile]{Removing reads}

\begin{tabular}{p{0.5\textwidth} p{0.5\textwidth}}

\begin{minted}[fontsize=\small]{c}
static int a;
void foo_1() {
  while (true) {
    int tmp = a;
    if (tmp == 0) break;
    do_something_with(tmp);
  }
}
\end{minted}

&

\end{tabular}

\pause

Could compiler avoid repated memory loads?

\end{frame}


\begin{frame}[t,fragile,noframenumbering]{Removing reads}

\begin{tabular}{p{0.5\textwidth} p{0.5\textwidth}}

\begin{minted}[fontsize=\small]{c}
static int a;
void foo_1() {
  while (true) {
    int tmp = a;
    if (tmp == 0) break;
    do_something_with(tmp);
  }
}
\end{minted}

&

\begin{minted}[fontsize=\small]{c}
static int a;
void foo_2() {
  int tmp = a;
  if (tmp != 0)
    while (true) { 
      do_something_with(tmp); 
    }
}
\end{minted}
\end{tabular}

Could compiler avoid repated memory loads?
\end{frame}


\begin{frame}[t, fragile, noframenumbering]{Removing reads}

\begin{tabular}{p{0.42\textwidth} p{0.5\textwidth}}


\begin{minted}[fontsize=\small]{c}
static int a;
void foo_1() {
  while (true) {
    int tmp = a;
    if (tmp == 0) break;
    do_something_with(tmp);
  }
}
\end{minted}

\texttt{x86-64 clang 16.0.0 -O2}\footnote{\tiny\url{https://godbolt.org/z/99j3erzaE}}

\texttt{x86-64 gcc 13.1 -O2}\footnote{\tiny\url{https://godbolt.org/z/fxzGEo1qf}}

&

\begin{minted}[fontsize=\small]{gas}
foo_1:                                  
    push    rbx
    mov     ebx, [a]
    test    ebx, ebx
    je      .LBB1_2
.LBB1_1:                       #<-|    
    mov     edi, ebx           #  |
    call    do_something_with  #  |
    jmp     .LBB1_1            #--|
.LBB1_2:
    pop     rbx
    ret
\end{minted}

\end{tabular}

\end{frame}



\begin{frame}[t, fragile]{Load hoisting}

\begin{tabular}{p{0.5\textwidth} p{0.5\textwidth}}

\begin{minted}[fontsize=\small]{c}
static int a;
void foo_1(bool c, int r1) {
  if (c) {
    r1 = a;
  }
}
\end{minted}

&

\begin{minted}[fontsize=\small]{c}
static int a;
void foo_2(bool c, int r1) {
  int t = a;
  r1 = c ? t : r1;
}
\end{minted}
\end{tabular}

\end{frame}


\begin{frame}[t, fragile]{CSE over lock}

\begin{tabular}{p{0.5\textwidth} p{0.5\textwidth}}

\begin{minted}[fontsize=\small]{c}
static int a;
void foo_1(bool c, int r1, int r2) {
   r1 = a;
   lock();
   r2 = a; 
}
\end{minted}

&

\begin{minted}[fontsize=\small]{c}
static int a;
void foo_2(bool c, int r1, int r2) {
   r1 = a;
   lock();
   r2 = r1; 
}
\end{minted}
\end{tabular}

\end{frame}


\begin{frame}[t, fragile]{Load hoisting + CSE over lock}

\begin{tabular}{p{0.30\textwidth} p{0.30\textwidth} p{0.35\textwidth}}

\begin{minted}[fontsize=\small]{c}
static int a;
void foo_1() {
   if (c) {
     r1 = a;
   }
   lock();
   r2 = a;
}
\end{minted}

&

\begin{minted}[fontsize=\small]{c}
static int a;
void foo_2() {
   int t = a;
   r1 = c ? t : r1;
   lock();
   r2 = a;
}
\end{minted}

 &

\begin{minted}[fontsize=\small]{c}
static int a;
void foo_3() {
  int t = a;
  r1 = c ? t : r1;
  lock();
  r2 = t;
}
\end{minted}
\end{tabular}

\pause

When \texttt{c == false}, \textbf{a} is moved out of the critical region!\footnote<2->{\tiny\url{https://people.mpi-sws.org/~viktor/slides/2017-09-concur.pdf}}

\end{frame}

\begin{frame}[t, fragile]{Compiler: friend or foe?}

Various optimizations of plain memory accesses
\begin{itemize}
  \pause \item invent reads or writes
  \pause \item remove reads or writes
  \pause \item reorder memory operations
\end{itemize}

\pause
make concurrent reasoning almost impossible 
\begin{itemize}
  \pause \item no \textbf{linearizability}
  \pause \item no \textbf{coherence}
  \pause \item no \textbf{eventual visibility} (a.k.a. \textbf{progress})
\end{itemize}

\end{frame}


\begin{frame}[t, fragile]{Taming compiler optimizations}

Compiler reorders language-level constructs
\begin{itemize}
  \pause
  \item to improve performance
  \pause
  \item but keep consistent single-threaded behaviour 
\end{itemize}

\pause
We need to inform compiler that some invariants are important for multi-threaded execution:
\begin{itemize}
  \pause \item do not reorder \textbf{this} and \textbf{that} operation (low-level consistency)
  \pause \item do not move operations out of critical sections (high-level consistency)
  \pause \item do not invent new operations
  \pause \item do not remove or merge some operations
\end{itemize}

\pause

We have already encountered such problems with reorderings of memory effects, remember?

\end{frame}

% \begin{frame}{Выдумывание операций}
% 
% 2. Схлопывает вычислений. Добавляет вычисления. Выносит из секций, заносит в секции.
% Имеет право на совсем странные вещи. OOTA, что-то там еще
% 
% \end{frame}

\section{Barriers: kinds and flavours}
\showTOC

\begin{frame}[t, fragile]{Barriers taxonomy: here we go again}

Simplified taxonomy of barriers\footnote{\tiny Could be misleading \url{https://shipilev.net/blog/2016/close-encounters-of-jmm-kind/}}:
\begin{itemize}
    \item \texttt{Store\_Store}, \texttt{Store\_Load}, \texttt{Load\_Store}, \texttt{Load\_Load}
\end{itemize}

\begin{tabular}{p{8cm}p{5cm}}

\begin{minted}{c}
  int x = static.data1;
  Store_Store();
  Store_Load();
  int y = static.data2;
  static.data3 = 17;
\end{minted}

 &

 \begin{minted}{c}
  int x = static.data1;
  Load_Load();

  int y = static.data2;
  static.data3 = 17;
\end{minted}

\end{tabular}
\end{frame}



\begin{frame}[t, fragile]{Compiler barriers}

\vspace{-0.5cm}
\begin{tabular}{p{0.5\textwidth} p{0.5\textwidth}}
\begin{minted}[fontsize=\small]{c}
int x, y;
void foo1() {
      x = 1;
      y = 2;
      x = 3;
}
\end{minted}

& 

\begin{minted}[fontsize=\small]{c}
int x, y;
void foo2() {
      x = 1;
      barrier();
      y = 2;
      x = 3;
}
\end{minted}
\end{tabular}

\pause
\vspace{-0.5cm}

\begin{tabular}{p{0.5\textwidth} p{0.5\textwidth}}

\begin{minted}[fontsize=\small]{gas}
foo1:
    mov [y], 2
    mov [x], 3
    ret
\end{minted}

& 

\begin{minted}[fontsize=\small]{gas}
foo2:
    mov [x], 1
    mov [y], 2
    mov [x], 3
    ret
\end{minted}
\end{tabular}

\pause

\textbf{Warning:} avoid such low-level tricks in modern programming languages!\footnote<3->{\tiny\url{https://preshing.com/20120625/memory-ordering-at-compile-time/}}

\end{frame}

\questiontime{

\begin{itemize}
  \item \texttt{mov [x], 1}
  \item \texttt{mov [y], 2}
  \item \texttt{mov [x], 3}
\end{itemize}

Name hardware-level optimizations that will "reorder" \ these memory operations.

}



\begin{frame}{Reorderings: everywhere}

Hardware
\begin{itemize}
  \pause \item anything could be reordered with everything
  \pause \item current CPU will "emulate" \ execution of single-threaded program "as if" \ in program order
  \pause \item single memory cell is \textbf{coherent} 
  \pause \item ordering could be enforced by memory barriers
\end{itemize}

\pause
Compiler
\begin{itemize}
  \pause \item anything could be reordered with everything
  \pause \item optimizations do not violate single-threaded behaviour   
  \pause \item some language constructs are \textbf{special} (e.g. \texttt{synchronized})
  \pause \item ordering could be enforced by compiler barriers
\end{itemize}

\pause
Looks like problem is already solved!

\pause

Reasoning about memory locations/compiler optimizations is mundane, complex and fragile, shouldn`t we use something better?

\end{frame}


\questiontime{Barriers enforce ordering of operations. But compiler could "invent" \ or "remove" \ operations which will break some concurrent invariants. What should we do?}


\begin{frame}{Consistency of memory operations in concurrent environment: challenges}

Programming language should be high-level enough and \textbf{should not} depend on
\begin{itemize}
  \pause \item Platform (different OSes, various CPU architectures)
  \pause \item Optimizer (compilers)
  \pause \item Runtime (memory management, RTTI, synchronization)
  \pause \item Language version (maybe)
\end{itemize}

\pause 
Programming language should be low-level enough and \textbf{should} provide
\begin{itemize}
  \pause \item Consistency guarantees for explicitly synchronized memory operations
  \pause \item Reasonable rules of concurrent execution  
\end{itemize}

\pause

We need language memory model

\end{frame}


\section{Language memory models}
\showTOCSub

\subsection{Goals and non-goals}


\begin{frame}{Language Memory Model}

\begin{itemize}
    \pause \item How to formalize it?
    \begin{itemize}
      \item Documentation in human language
      \item Machine-readable format
      \item Executable algorithm
      \item Set of optimizer rules
    \end{itemize}     
    \pause \item Prefer strict rules or use weak models?
    \pause \item How to check consistency of memory model itself?
    \pause \item How to guarantee that every program could be unambiguously described?
    \pause \item How to explain the rules to language users?
\end{itemize}

\pause

There is no \textit{perfect} programming language.

\pause

Any language tries to be \textit{performant}, \textit{safe}, \textit{user-friendly}, \textit{stable} ...

\end{frame}


\subsection{Partial memory model: bad things can not be expressed}
\showTOCSub

\begin{frame}[fragile, t]{No man, no problem}

Concurrency is complicated only when we have non-trivial communication
\begin{itemize}
  \item via shared memory locations
  \item via concurrent primitives
\end{itemize}

\pause

Use plain and simple approaches

\begin{itemize}
  \pause \item immutable data structures
  \pause \item declarative description of computation
\end{itemize}

\pause SQL \pause , Clojure \pause , Haskell

\pause
\begin{quote}
All told, a monad in X is just a monoid in the category of endofunctors of X, with product × replaced by composition of endofunctors and unit set by the identity endofunctor.
\end{quote}

\pause
Is it about \textit{language} or \textit{programming style}?
\end{frame}

\begin{frame}[fragile, t]{Immutability}

Immutable data structure
\begin{itemize}
  \pause \item different threads could simultaneously read
  \pause \item conflicts (data races) are impossible
\end{itemize}

\pause
How to update such data structure when something happens?
\begin{itemize}
  \pause \item Create new immutable instance with up-to-date information
\end{itemize}

\pause
Few problems
\begin{itemize}
  \pause \item Overheads for creation of large data structures
  \pause \item "Publish" \ data structure for all threads  == write to shared memory location
\end{itemize}

\end{frame}

\begin{frame}[fragile, t]{Declarative DSL}

\texttt{java.util.stream}\footnote{\tiny\url{https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/stream/package-summary.html}}

\begin{minted}{java}
int sumOfWeights = widgets.parallelStream()
                          .filter(b -> b.getColor() == RED)
                          .mapToInt(b -> b.getWeight())
                          .sum();
\end{minted}

\pause

Solve any embarrassingly parallel problem in few readable lines.

\pause

All safety and efficiency will happen under the hood.

\end{frame}

\begin{frame}[fragile, t,noframenumbering]{Declarative DSL}


Solve any embarrassingly parallel problem in few readable lines.

\pause
\begin{itemize}
  \item Java parallel streams {\tiny\url{https://docs.oracle.com/javase/tutorial/collections/streams/parallelism.html}}
  \item OpenMP {\tiny\url{https://www.openmp.org/}}
  \item Intel TBB {\tiny\url{https://github.com/oneapi-src/oneTBB}}
  \item MPI {\tiny\url{https://www.open-mpi.org/}}
  \item MapReduce {\tiny\url{https://research.google/pubs/pub62/}}
  \item Resilient Distributed Datasets {\tiny\url{https://dl.acm.org/doi/10.5555/2228298.2228301}}
\end{itemize}

\pause
\textbf{First and obvious} choice for any language and any application. \pause Unless it does not fit.

\pause
Implementations of such DSL are concurrently writing to shared memory locations.
\end{frame}

\begin{frame}[t]{Actor model}

Programming model with no shared state\footnote{\tiny\url{https://en.wikipedia.org/wiki/Actor_model}}.

\pause

All computational agents (lightweight processes) are independent and communicate via message passing.

\end{frame}

\questiontime{Name your favourite concurrent message-passing protocol}

\begin{frame}[t,noframenumbering]{Actor model}

Programming model with no shared state.

All computational agents (lightweight processes) are independent and comunicate via message passing.

\pause
\begin{itemize}
  \item Erlang\footnote<2->{\tiny\url{https://www.erlang.org/}}
  \item Akka actors\footnote<2->{\tiny\url{https://doc.akka.io/docs/akka/current/typed/actors.html#akka-actors}}
\end{itemize}

\pause

Implementations of such systems are concurrently writing to shared memory locations.

\end{frame}


\subsection{Partial memory model: bad things should be avoided}
\showTOCSub

\begin{frame}[fragile, t]{Be in Sync or Die Tryin}

Swift\footnote{\tiny\url{https://github.com/apple/swift-evolution/blob/main/proposals/0282-atomics.md}}

\only<1> {
\begin{quote}
Concurrent write/write or read/write access to the same location in memory generally remains undefined/illegal behavior, unless all such access is done through a special set of primitive atomic operations.
\end{quote}
}

\only<2> {
\begin{quote}
Concurrent write/write \sout{or read/write} access to the same location \sout{in memory generally} remains \sout{undefined/}illegal behavior, unless \sout{all such access} is done through \sout{a special set of primitive} atomic operations.
\end{quote} 
}

\only<3->{
\begin{quote}
Concurrent write/write access to the same location remains illegal behavior, unless is done through atomic operations.
\end{quote}
}

\begin{onlyenv}<4->
\begin{minted}[fontsize=\small]{swift}
import Foundation
class Bird {}
var S = Bird()
let q = DispatchQueue.global(qos: .default)
q.async { while(true) { S = Bird() } }
while(true) { S = Bird() }
\end{minted}
\end{onlyenv}

\only<5->{
Concurrent writes are violating naive implementation of automatic reference counting\footnote<5->{\tiny\url{https://tonygoold.github.io/arcempire/}}\textsuperscript{,}\footnote<5->{\tiny\url{https://github.com/apple/swift/blob/main/docs/proposals/Concurrency.rst}}. Program crashes with \texttt{double free or corruption}.
}

\end{frame}

\subsection{Strict consistency: GIL}
\showTOCSub

\begin{frame}[fragile, t]{Mutex-based strict consistency}

Strict consistency -- all operations happens atomically and have total order\footnote{\tiny\url{https://en.wikipedia.org/wiki/Consistency_model#Strict_consistency}}.

\end{frame}


\begin{frame}[fragile, t, noframenumbering]{Mutex-based strict consistency}

Strict consistency -- all operations happens atomically and have total order.

\begin{tabular}{p{0.5\textwidth} p{0.5\textwidth}}

\begin{minted}[fontsize=\small]{c}
void thread1() {

  foo();
  

  bar();

}
\end{minted}

&

\begin{minted}[fontsize=\small]{c}
void thread2() {

  baz();
  

  foo();

}
\end{minted}

\end{tabular}

\end{frame}

\begin{frame}[fragile, t, noframenumbering]{Mutex-based strict consistency}

Strict consistency -- all operations happens atomically and have total order.
\begin{tabular}{p{0.5\textwidth} p{0.5\textwidth}}

\begin{minted}[fontsize=\small]{c}
void thread1() {
  lock();
  foo();
  unlock();
  lock();
  bar();
  unlock();
}
\end{minted}

&

\begin{minted}[fontsize=\small]{c}
void thread2() {
  lock();
  baz();
  unlock();
  lock();
  foo();
  unlock();
}
\end{minted}

\end{tabular}

\end{frame}

\begin{frame}[fragile, t, noframenumbering]{Mutex-based strict consistency}

Strict consistency -- all operations happens atomically and have total order.

\begin{tabular}{p{0.5\textwidth} p{0.5\textwidth}}

\begin{minted}[fontsize=\small]{c}
void thread1() {
  GIL.lock();
  foo();
  GIL.unlock();
  GIL.lock();
  bar();
  GIL.unlock();
}
\end{minted}

&

\begin{minted}[fontsize=\small]{c}
void thread2() {
  GIL.lock();
  baz();
  GIL.unlock();
  GIL.lock();
  foo();
  GIL.unlock();
}
\end{minted}

\end{tabular}

Global mutex guards every "instruction"


\end{frame}

\begin{frame}[fragile, t, noframenumbering]{Mutex-based strict consistency}

Strict consistency -- all operations happens atomically and have total order.

Global Interpreter Lock (GIL)\footnote{\tiny\url{https://en.wikipedia.org/wiki/Global_interpreter_lock}} guards every "instruction"
 
\pause

Language do have threads\footnote<2->{\tiny\url{https://docs.python.org/3/library/threading.html}}, they are "concurrent but not parallel"

\pause

GIL is technical decision that may highly influence the whole ecosystem
\begin{itemize}
  \item Alternative language implementations\footnote<3->{\tiny\url{https://doc.pypy.org/en/latest/faq.html#does-pypy-have-a-gil-why}}
  \item Memory model\footnote<3->{\tiny\url{https://peps.python.org/pep-0583/}}
  \item Interoperability with other languages\footnote<3->{\tiny\url{https://peps.python.org/pep-0703/}}
\end{itemize}

\end{frame}


\subsection{Strict consistency: Event Loop}
\showTOCSub

\begin{frame}[fragile, t]{Single-threaded strict consistency}

Strict consistency -- all operations happen atomically and have total order.

\begin{itemize}
  \pause \item Forbid multithreading on language level
  \pause \item The only thread processes events, every event could create other (possibly delayed) events
  \pause \item JavaScript Event Loop\footnote<4->{\tiny\url{https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Execution_model}}
\end{itemize}

\pause
\begin{quote}
Each job is processed completely before any other job is processed. This offers some nice properties when reasoning about your program, including the fact that whenever a function runs, it cannot be  preempted and will run entirely before any other code runs (and can modify data the function manipulates). 
\end{quote}

\end{frame}


\begin{frame}[fragile, t,noframenumbering]{Single-threaded strict consistency}

Strict consistency -- all operations happen atomically and have total order.

\begin{itemize}
  \item Forbid multithreading on language level
  \item The only thread processes events, every event could create other (possibly delayed) events
  \item JavaScript Event Loop
\end{itemize}

\pause

If you need parallelism -- use dedicated API\footnote<2->{\tiny\url{https://www.w3schools.com/html/html5_webworkers.asp}}
\begin{itemize}
  \pause \item Safety -- message passing with data copying\footnote<3->{\tiny\url{https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Structured_clone_algorithm}}
  \pause \item Performance -- shared byte array\footnote<4->{\tiny\url{https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/SharedArrayBuffer}} + atomics\footnote<4->{\tiny\url{https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Atomics}}
\end{itemize}

\pause
As soon as you have concurrent access -- you immediately encounter "serious" \ problems\footnote<5->{\tiny "Repairing and Mechanising the JavaScript Relaxed Memory Model"\ \url{https://arxiv.org/abs/2005.10554}}

\end{frame}


\subsection{Partial memory model: threading as a service}
\showTOCSub

\begin{frame}[t]{Threads as a library}

C/С++ before C++11\footnote{\tiny\url{https://en.wikipedia.org/wiki/C\%2B\%2B11#Multithreading_memory_model}}

\pause
\begin{itemize}
  \item There were no threads in language specification
  \begin{itemize}
    \item There were libraries that implement threading
  \end{itemize}  
  \item Every project was free to invent custom designs, data structures, conventions
  \begin{itemize}
    \item Compiler-specific
    \item CPU-specific
    \item OS-specific
  \end{itemize}    
  \item Any data race is undefined behaviour
\end{itemize}

\end{frame}


\begin{frame}[t]{Threads as universal library}

C/С++ before concurrent specifications + POSIX threads\footnote{\tiny\url{https://en.wikipedia.org/wiki/Pthreads}}

\pause
\begin{itemize}
  \item There were no threads in language specification
  \begin{itemize}
    \item There was \textbf{universal} library to implement threading
  \end{itemize}
  \item Portable solution
  \item Any data race is undefined behaviour. Use mutexes, Luke!  
\end{itemize}

\pause
Do not underestimate the complexity of implementing such library\footnote<3->{\tiny\url{https://probablydance.com/2020/10/31/using-tla-in-the-real-world-to-understand-a-glibc-bug/}}\textsuperscript{,}\footnote<3->{\tiny\url{https://probablydance.com/2022/09/17/finding-the-second-bug-in-glibcs-condition-variable/}}

\pause

"Threads Cannot Be Implemented As a Library"\footnote<4->{\tiny\url{https://www.hpl.hp.com/techreports/2004/HPL-2004-209.pdf}}
\pause

\begin{quote}
 The Pthreads specification prohibits races, i.e. accesses to a shared variable while another thread is modifying it. ... the
 problem here is that whether or not a race exists depends on the semantics of the programming language, which in turn requires that we have a properly defined memory model.
 Thus this definition is circular.
\end{quote}

\end{frame}


\subsection{Partial memory model: concurrency-aware language subset}
\showTOCSub


\begin{frame}{Explicit concurrent operations}

Specify subset of programming language that provides consistent multithreaded execution.

\begin{itemize}
\pause \item C/C++ atomics
\pause \item Swift/ObjC NSLocking
\pause \item Java-1996 volatile
\end{itemize}

\pause
Part of a \textbf{language}, not just a library!

\pause
Not that easy to do: "The Java Memory Model is Fatally Flawed"\ , William Pugh, 2000\footnote<6->{\tiny\url{http://www.cs.umd.edu/~pugh/java/broken.pdf}}

\end{frame}

\subsection{Memory model: concurrency embedded into language}
\showTOCSub

\begin{frame}{Formal language memory model}

Mathematics to the max
\begin{itemize}
  \pause \item An action \textit{a} is described by a tuple $\langle t, k, v, u\rangle$ comprising ...\
  \pause \item Partial and linear orders; transitive closure of binary relations; happens-before
  \pause \item Causality requirements, circular happens-before, out-of-thin-air problem
  \pause \item Adaptation to h/w models\footnote<5->{\tiny"JSR-133 Cookbook for Compiler Writers"\ \url{https://gee.cs.oswego.edu/dl/jmm/cookbook.html}}
  \pause \item Every data race is specified: allowed and forbidden outcomes
\end{itemize}

\pause
Few problems
\begin{itemize}
  \item Complicated, takes a lot of time, expensive to maintain
  \item Not ideal\footnote<7->{\tiny"Java Memory Model Examples: Good, Bad and Ugly"\ \url{https://groups.inf.ed.ac.uk/request/jmmexamples.pdf}}
  \item Hard to explain, hard to use in practice
\end{itemize}
\end{frame}


\begin{frame}[t]{Formal Memory Models: useful?}

Goals of our 1-semester introductory course to concurrency
\begin{itemize}
  \pause
  \item Show how to write
  \begin{itemize}
    \item correct
    \item \textbf{understandable}
    \item performant
  \end{itemize}
  concurrent code

  \pause
  \item Show \textbf{basic} concurrent concepts

  \pause
  \item Convince to use simple rather complicated approaches
\end{itemize}

\pause
Non-goals
\begin{itemize}
  \pause \item Look smart and mathematically inclined
  \pause \item Study state-of-the art concurrency 
  \pause \item Achieve top performance in our concurrent programs
\end{itemize}

\pause

Studying concurrent consistency, proving theorems on Lecture~\foundationsNum \ and Lecture~\foundationsPlusNum, analyzing cache coherence was enough.

\end{frame}

\begin{frame}{Patterns}

Doug Lea, private communication with Aleksey Shipilev, 2013\footnote{\tiny Citation from \url{https://shipilev.net/blog/2014/jmm-pragmatics}, slide 109}

\begin{quote}
The best way to build up a small repertoire of constructions that you know the answers for and then never think about the JMM rules again unless you are forced to do so! Literally nobody likes figuring things out from the JMM rules as stated, or can even routinely do so correctly.
This is one of the many reasons we need to overhaul JMM someday.
\end{quote}
\end{frame}


\begin{frame}{Concurrent patterns}

Could be found in books
\begin{itemize}
  \item "Java Concurrency in Practice"
  \item "Effective Java"
  \item "The Art of Multiprocessor Programming"
  \item "Is Parallel Programming Hard, And, If So, What Can You Do About It?"
\end{itemize}

Could be found in documentation \texttt{java.util.concurrent}

We studied this
\begin{itemize}
  \item \texttt{Lock, Condition} (Lecture~\basicNum)
  \item advanced concurrent primitives (Lecture~\syncPrimitivesNum)
  \item producer-consumer, load balancing, partitioning, replication (Lecture~\syncPrimitivesNum \ and Lecture~\patternsNum)
\end{itemize}

\end{frame}


\section{Advanced topics}

\subsection{Visibility}
\showTOCSub

\begin{frame}[t,fragile]{Visibility}

\begin{minted}{java}
class Data { long x; }
static Data shared;
void threadA() {
  Data d = new Data();
  d.x = 42;
  shared = d;
}
void threadB() {
  System.out.println(shared.x);
}
\end{minted}

\pause

Do you see race condition that prevents \texttt{threadB} from printing integer?

\pause

\texttt{NullPointerException}

\end{frame}


\begin{frame}[t,fragile,noframenumbering]{Visibility}

\begin{minted}{java}
class Data { long x; }
static Data shared;
void threadA() {
  Data d = new Data();
  d.x = (1L << 40) + 1;
  shared = d;
}
void threadB() {
  System.out.println(shared.x);
}
\end{minted}

\begin{itemize}
  \pause \item Could program print \texttt{1}?
  \pause \item Could program print \texttt{1099511627776} (\texttt{1 << 40})?
  \pause \item Could program print \texttt{1099511627777}?
\end{itemize}

\end{frame}

\begin{frame}[t,fragile,noframenumbering]{Visibility}

\begin{minted}{java}
class Data { long x; }
static Data shared;
void threadA() {
  Data d = new Data();
  d.x = 42;
  shared = d;
}
void threadB() {
  System.out.println(shared.x);
}
\end{minted}

\pause

\begin{itemize}
  \item Program prints \texttt{0}
  \item Explain this using some hardware optimization 
  \begin{itemize}
    \item store buffering, load buffering, invalidate queue, interconnect topology
  \end{itemize}
\end{itemize}
\end{frame}


\begin{frame}[t,fragile,noframenumbering]{Visibility}
\begin{minted}{java}
class Data { long x; }
static Data shared;
void threadA() {
  Data d = new Data();
  d.x = 42;
  shared = d;
}
void threadB() {
  System.out.println(shared.x);
}
\end{minted}


\begin{itemize}
  \item Program prints \texttt{0}
  \item Explain this using some compiler optimization
\end{itemize}
\end{frame}


\begin{frame}[t,fragile]{Visibility: trust nobody}

Non-synchronized concurrent access to any memory location
\begin{itemize}
  \item Static field
  \item Instance field
  \item Array element
\end{itemize}
could lead to subtle and hard-to-diagnose bugs.
\end{frame}

\questiontime{Which Java-specific concepts help you to avoid visibility problems?}

\begin{frame}[t,fragile, noframenumbering]{Visibility: trust friends only}

Non-synchronized concurrent access to any memory location
\begin{itemize}
  \item Static field
  \item Instance field
  \item Array element
\end{itemize}
could lead to subtle and hard-to-diagnose bugs.

Synchronization operations:
\begin{itemize}
  \item \texttt{Thread.start}, \texttt{Thread.join}
  \item \texttt{Lock.lock}, \texttt{Lock.unlock} and other \texttt{java.util.concurrent} primitives
  \item \texttt{synchronized}
  \item \texttt{AtomicLong, AtomicReference} read-modify-write operations
\end{itemize}

\pause

By default\footnote<2->{Consult with javadoc first} they act as full barrier \pause and as a linearization point

\end{frame}

\subsection{Volatile}
\showTOCSub

\begin{frame}[t,fragile]{Using memory location as synchronization point}

\begin{minted}{java}
class LockPreReservedByB { boolean busy = true; }
static LockPreReservedByB lock; static Data data;
void threadA() {  while (lock.busy) { /*await*/ } // lock.lock()
                  Data x = data;  
}
void threadB() {  Data d = new Data(); d.x = 42;
                  data = d;
                  lock.busy = false; // lock.unlock()
}
\end{minted}

\pause

We need 
\begin{itemize}
  \item \texttt{Lock.unlock} to act as publishing memory barrier (store release)
  \item \texttt{Lock.lock} to repair consistency of data being read (load acquire)
  \item all operations with \texttt{lock.busy} to be ordered (linear order)
\end{itemize}
\end{frame}


\begin{frame}[t,fragile]{Using memory location as synchronization point}

Roach motel idiom\footnote{\tiny\url{https://shipilev.net/talks/narnia-2555-jmm-pragmatics-en.pdf}}

\begin{minted}{java}
int a; volatile boolean ready = false;
void threadA() {
  a = 41;
  a = 42;
  ready = true; // release data. Every write above will be visible (flushed)
  a = 43;
}
void threadB() {
  while (!ready) {} // acquire data. Every read below will see up-to-date data
  println(a);
}
\end{minted}

\pause

Possible to see \texttt{42} or \texttt{43}. Impossible to see \texttt{0} or \texttt{41}.

\end{frame}

\begin{frame}[t,fragile]{Volatile}

\texttt{volatile} variable
\begin{itemize}
  \item \texttt{volatile} mode accesses are totally ordered
  \begin{itemize}
    \item coherence, visibility (progress)
  \end{itemize}
  \item not a plain variable, enforces some ordering with other locations 
  \begin{itemize}
    \item load acquire, store release
  \end{itemize}
  \item not an atomic read-modify-write variable, does not provide full barrier semantics
\end{itemize}

\pause
Kinda \textit{weak}
\begin{itemize}
  \item advanced protocols
  \item performance
\end{itemize}

\pause

Very Java-specific
\begin{itemize}
  \item \texttt{volatile} in C/C++ is \textbf{absolutely different}
  \item \texttt{memory\_order\_acq\_rel} in C/C++ is \textbf{subtly different} from Java \texttt{volatile}
  \item many languages are OK with plain variables and full-fence variables
  \item low-level languages allow to use atomic RMW variables with different "strength"  
\end{itemize}

\end{frame}


\begin{frame}[t,fragile]{Volatile: rules of thumb}

\begin{itemize}
  \pause \item use \texttt{volatile} only when it simplify your synchronization policy
  \pause \item avoid \texttt{volatile} when veryfing correctness would require subtle reasoning about visibility
  \pause \item good uses of \texttt{volatile} include ensuring the visibility of their own state or indicating that an important life-cycle event (such as initialization or shutdown) has occurred
\end{itemize}

\pause
\begin{minted}{java}
volatile boolean asleep;
...
while (!asleep) {
  countSomeSheep();
}
\end{minted}

\pause
You can use \texttt{volatile} variables only when all the following criteria are met:
\begin{itemize}
  \pause \item writes to the variable do not depend on its current value, or you can ensure that only a single thread ever updates the value
  \pause \item the variable does not participate in invariants with other state variables
  \pause \item locking is not required for any other reason while the variable is being accessed
\end{itemize}

\end{frame}

% \subsection{(Optional): safe publication and safe initialization}
% \showTOCSub
% 
% \begin{frame}[t,fragile]{Volatile}
% 
% To publish an object safely, both the reference to the object and the ob-
% ject’s state must be made visible to other threads at the same time. A
% properly constructed object can be safely published by:
% • Initializing an object reference from a static initializer;
% • Storing a reference to it into a volatile field or AtomicReference;
% • Storing a reference to it into a final field of a properly constructed
% object; or
% • Storing a reference to it into a field that is properly guarded by a
% lock.
% 
% 
% 
% https://shipilev.net/blog/2014/safe-public-construction/
% 
% 
% \end{frame}


\section{Summary}

\begin{frame}{Summary}

Compiler optimizations
\begin{itemize}
 \item reorder/invent/delete memory operations, prevent it via compiler barriers
\end{itemize}

Language memory model -- bridge between
\begin{itemize}  
    \item chaos of hardware, anarchy of compiler optimizations    
    \item consistency requirements for high-level concurrent algorithms       
\end{itemize}

Useful concepts
\begin{itemize}
  \item immutability
  \item DSL for parallel computations
  \item strict consistency via mutex
  \item strict consistency via single executor and cooperative multitasking
  \item threads cannot be implemented as a library
  \item language memory model is harder to formalize than hardware memory model
  \item visibility is subtle but critically important
  \item \texttt{volatile} is for hackers
\end{itemize}

\end{frame}


\begin{frame}{The most efficient and elegant approach to writing concurrent code}
\begin{center}
\url{https://go.dev/ref/mem}
\end{center}

\pause
\begin{center}
\textbf{Don't be clever}
\end{center}



\end{frame}




% \begin{frame}{Summary}
% we had problems with visibility and compiler optimization/reordering (lec~TODO)
% 
% we had problems with hardware visibility and reordering (lec~TODO)
% 
% we developed formalisms to discuss what is "ordered" (data- control-flow- dependent) and what is "simultanous" (independent, arbitrary)
% 
% we found out that we may need primitives of different "strength", depending on out goals (plain filed access, atomic registers, common2 RMW, CAS)
% 
% How to program on programming language that allows concurrency (e.g. start of threads or sheduling of async operations or preemtive executions via l/w threads or ...)
% 
% - how to program reliable programs
% - how to program efficient programs
% - how to program mainatable programs (w.r.t. modification of users, w.r.t evolution of language)
% 
% High-level abstractions power:
% - mach code, assembler, low-level unmanaged language, middle-level portable language, high-level language, domain-specific declarative language
% 
% Less you need to know -- you are more productive and efficient in *problem-solving* 
% 
% \end{frame}


% \begin{frame}{Concurrency and lazy evaluation}
% TODO: add this slide
% \end{frame}



% \begin{frame}{Conclusion}
% 
% Effectively, less knowledge is required to understand your code -- the better.
% 
% However, to generate such code you indeed need to know a lot of advanced stuff just to cover a lot of requirements
% - perf
% - corectnes
% - flexibility
% 
% One solution is yo use existing primitives
% 
% Other is to use clasical patterns with default naming and conventions
% 
% Third soluction to encapsualte advanced stuff into modules with clear contract and several impl (inluding trivial bullet-roof one)
% 
% Fourth approach is to reformulate the problem or design of a system to avoid concurrency
% 
% 
% In any case you WILL write some code. And here you need guarantees that it works as intended (and continue to work on other plaform/hardware/OS/cpufreq/scheduler etc)
% 
% That is why you need some form of language memoey model
% - few guaranteed pattern (litmus-test alike)
% - language subset with clear properties (DRF-SC)
% - full description of all outcomes in all cases (formal mem model)
% 
% In ideal world, this description is used by specialized tools (static analzyzers, dynamic analyzers) to find bugs in software (semi-) automatically
% 
% In real world sometimes you have only choice to
% - encapsualte
% - guard asserts
% - test sute
% - document policies
% 
% \end{frame}


\end{document}
